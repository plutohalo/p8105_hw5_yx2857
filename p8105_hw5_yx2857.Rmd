---
title: "p8105_hw5_yx2857"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

```{r packages}
libaries = c(
  "tidyverse",
  "broom"
)
set.seed(2857)
```

# Problem 1. 
```{r q1}
# Suppose you put 𝑛people in a room, and want to know the probability that at least two people share a birthday. For simplicity, we’ll assume there are no leap years (i.e. there are only 365 days) and that birthdays are uniformly distributed over the year (which is actually not the case).

# Write a function that, for a fixed group size, randomly draws “birthdays” for each person; checks whether there are duplicate birthdays in the group; and returns TRUE or FALSE based on the result.

# Next, run this function 10000 times for each group size between 2 and 50. For each group size, compute the probability that at least two people in the group will share a birthday by averaging across the 10000 simulation runs. Make a plot showing the probability as a function of group size, and comment on your results.


```

# Problem 2.  

```{r q2}
# When designing an experiment or analysis, a common question is whether it is likely that a true effect will be detected – put differently, whether a false null hypothesis will be rejected. The probability that a false null hypothesis is rejected is referred to as power, and it depends on several factors, including: the sample size; the effect size; and the error variance. In this problem, you will conduct a simulation to explore power in a one-sample t-test.
 
# First set the following design elements:
# 

# Generate 5000 datasets from the model 𝑥∼𝑁𝑜𝑟𝑚𝑎𝑙[𝜇,𝜎] # Fix 𝑛=30, 𝜎=5 and Set 𝜇=0

# Function generate random samples, substracting mean and p-value
sim_mean_p = function(samp_size = 30, true_mean = 0, true_sd = 5, mu = 0) {
  
  sim_df = 
    tibble(
      x = rnorm(samp_size, true_mean, true_sd)
    )

  s_mean = 
    sim_df |> 
    summarize(
      samp_mean = mean(x),
      p_val = t.test(x, mu = mu)|>broom::tidy()|>pull(p.value)|>round(3)
    )
  
  return(s_mean)
}

# Set iteration
n <- 100

sim_res_0 <- tibble(
  iter = 1:n) |> 
  mutate(samp_res = map(iter, ~sim_mean_p(samp_size = 30, true_mean = 0, true_sd = 5, mu = 0))) |> 
  unnest(samp_res) 


# Parameters
n <- 100
mu_values <- 0:6

# Generate a list of tibbles for each value of mu
sim_res_list <- map(mu_values, function(mu) {
  tibble(
    iter = 1:n
  ) |> 
    mutate(samp_res = map(iter, ~sim_mean_p(samp_size = 30, true_mean = mu, true_sd = 5, mu = mu))) |> 
    unnest(samp_res)
})

# Name the list based on mu values
names(sim_res_list) <- paste0("mu_", mu_values)



# Combine all results into a single tibble with an additional column for `mu`
combined_results <- bind_rows(
  map2(sim_res_list, mu_values, ~mutate(.x, mu = .y))
)


```


```{r}
# Make a plot showing the proportion of times the null was rejected (the power of the test) on the y axis and the true value of mu on the x axis. Describe the association between effect size and power.
combined_results |> group_by(mu) |>
  summarize(power = mean(p_val < 0.05)) |> 
  ggplot(aes(x = mu, y = power)) + geom_point() + geom_line() + labs(title = "Power of the test", x = "True value of mu", y = "Proportion of times the null was rejected")
```
The association between the effect size and power is positive. As the true value of mu increases, the power of the test also increases. This is because the larger the effect size, the more likely the null hypothesis will be rejected.  

```{r}
# Make a plot showing the average estimate of 𝜇̂ 
#  on the y axis and the true value of 𝜇 on the x axis. 

#  Make a second plot (or overlay on the first) the average estimate of 𝜇̂ only in samples for which the null was rejected on the y axis and the true value of 𝜇 on the x axis. Is the sample average of 𝜇̂ across tests for which the null is rejected approximately equal to the true value of 𝜇? Why or why not?


combined_results |> group_by(mu) |>
  summarize(est_mu = mean(samp_mean)) |> 
  ggplot(aes(x = mu, y = est_mu)) + geom_point() + geom_line() + labs(title = "Average estimate of mu", x = "True value of mu", y = "Average estimate of mu")

combined_results |> filter(p_val < 0.05) |> group_by(mu) |>
  summarize(est_mu = mean(samp_mean)) |> 
  ggplot(aes(x = mu, y = est_mu)) + geom_point() + geom_line() + labs(title = "Average estimate of mu in samples for which the null was rejected", x = "True value of mu", y = "Average estimate of mu")

# overlay the second plot on the first plot
combined_results |> group_by(mu) |>
  summarize(est_mu = mean(samp_mean)) |> 
  ggplot(aes(x = mu, y = est_mu)) + geom_point() + geom_line() + labs(title = "Average estimate of mu and average estimate of the null-rejected", x = "True value of mu", y = "Average estimate of mu") + 
  geom_line(data = combined_results |> filter(p_val < 0.05) |> group_by(mu) |>
               summarize(est_mu = mean(samp_mean)), aes(x = mu, y = est_mu), color = "red")
# Is the sample average of 𝜇̂ across tests for which the null is rejected approximately equal to the true value of 𝜇? Why or why not?
```
The sample average of mu across tests for which the null is rejected is not approximately equal to the true value of mu. This is because the sample average of mu is an estimate of the true value of mu, and it is subject to sampling variability. The sample average of mu in samples for which the null is rejected is an estimate of the true value of mu in the subset of samples for which the null is rejected. This estimate is also subject to sampling variability, and it may not be equal to the true value of mu.  


